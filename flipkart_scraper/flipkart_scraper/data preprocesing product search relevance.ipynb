{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b626da",
   "metadata": {},
   "source": [
    "# Data preprocesing  and cleaning\n",
    "\n",
    "- In this notebook we post process the gathered product data from the scrapy spider\n",
    "- And find the relevant products using NLP or rules\n",
    "- Reference - https://github.com/jithinanievarghese/product-search-relevance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47ff576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rapidfuzz import fuzz\n",
    "from csv import QUOTE_ALL\n",
    "from time import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756052ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample(df):\n",
    "    \"\"\"\n",
    "    return sample view of dataframe\n",
    "    \"\"\"\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "    sample_df = df.sample(1)\n",
    "    for row , col in zip(sample_df.values[0], sample_df.columns):\n",
    "        print(f'{BOLD}{col}{END}\\n\\n{row}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a799f4",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30498755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"outputs/listing_data.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3bb67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2460 entries, 0 to 2459\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   title                  2460 non-null   object\n",
      " 1   subtitle               2328 non-null   object\n",
      " 2   product_url            2460 non-null   object\n",
      " 3   smart_url              2460 non-null   object\n",
      " 4   product_id             2460 non-null   object\n",
      " 5   image_url              2460 non-null   object\n",
      " 6   total_count            2460 non-null   int64 \n",
      " 7   next_listing_page_url  2399 non-null   object\n",
      " 8   search_query           2460 non-null   object\n",
      " 9   page                   2460 non-null   int64 \n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 192.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d402d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mtitle\u001b[0m\n",
      "\n",
      "Aapaga Magic 2x2 High Speed Cube Puzzle Toy for Kids & Adults | 2x2x2 Stickerless cubes\n",
      "\n",
      "\u001b[1msubtitle\u001b[0m\n",
      "\n",
      "1 Pieces\n",
      "\n",
      "\u001b[1mproduct_url\u001b[0m\n",
      "\n",
      "https://www.flipkart.com/aapaga-magic-2x2-high-speed-cube-puzzle-toy-kids-adults-2x2x2-stickerless-cubes/p/itmdd0a15ea444d2?pid=PUZGAH8VZZQBQQ4B\n",
      "\n",
      "\u001b[1msmart_url\u001b[0m\n",
      "\n",
      "http://dl.flipkart.com/dl/aapaga-magic-2x2-high-speed-cube-puzzle-toy-kids-adults-2x2x2-stickerless-cubes/p/itmdd0a15ea444d2?pid=PUZGAH8VZZQBQQ4B\n",
      "\n",
      "\u001b[1mproduct_id\u001b[0m\n",
      "\n",
      "PUZGAH8VZZQBQQ4B\n",
      "\n",
      "\u001b[1mimage_url\u001b[0m\n",
      "\n",
      "http://rukmini1.flixcart.com/image/612/612/kybvo280/puzzle/k/h/g/1-magic-2x2-high-speed-cube-puzzle-toy-for-kids-adults-2x2x2-original-imagah8vuem6tfg5.jpeg?q=70\n",
      "\n",
      "\u001b[1mtotal_count\u001b[0m\n",
      "\n",
      "322\n",
      "\n",
      "\u001b[1mnext_listing_page_url\u001b[0m\n",
      "\n",
      "https://www.flipkart.com/search?q=spider+man+car+toy&page=4\n",
      "\n",
      "\u001b[1msearch_query\u001b[0m\n",
      "\n",
      "spider man car toy\n",
      "\n",
      "\u001b[1mpage\u001b[0m\n",
      "\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9f17866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=[\"product_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4df9c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RVM Toys Spiderman Bobble Head Action Figure Toy Showpiece Bobblehead For Car / Office',\n",
       "       'Aapaga Action Figure Super Heros Toy Set | Inspired By Avengers Marvel Characters Iron Man, Hulk, Thor, Captain America And Ant Man Toys Collection For Kids | Multi-Color | Size: 4.5 Inches | Set Of 5',\n",
       "       'Daiyamondo Red Spider Spring Head Moving Had Bobble head Spring Dancing PVC Bobble Spring Dancing Doll Toy Car Dashboard Bounce Toys for Car Interior Dashboard Expression BobbleHead (Multicolor)',\n",
       "       ...,\n",
       "       'SUBH-ARAMBH SUPER HERO (SPIDER MAN) UNBREAKABLE FRICTION POWERED TOY CAR WITH MOVING HEAD',\n",
       "       'PITARA Spider Men Pressure Powered Press The Head Kids Toddler Car Toy',\n",
       "       'Aseenaa Angry Bird Study Game Toy laptop With Music And Alphabet Sound And Lights for new Kids | Educational mini Laptops | Learning small computer gaming Toys | Best Gift For boys girls Toddler kid | Color Multi'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d47918e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2233, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8fe5a0",
   "metadata": {},
   "source": [
    "# Image Data Saved or Upload Status\n",
    " - Here we used Deta Cloud Drive (https://www.deta.sh/)  for uploading the images of products while scraping\n",
    " - We can also save the data in local if there is no Deta project key\n",
    " - we also checked whether there is any missing in the product image data, by comparing with the product details dataset\n",
    " - some of the products had duplicated images so the there is less count in image datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca585e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upload_status = pd.read_json(\"outputs/upload_status.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b45658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_status.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a868d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.image_url) - set(upload_status.image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f76a6",
   "metadata": {},
   "source": [
    "# Data Cleaning and string matching\n",
    "\n",
    "- We can either use string_match_with_rules() or string_match_with_fuzz(). \n",
    "\n",
    "### string_match_with_rules()\n",
    "- Uses a rule searching simple approach\n",
    "- With help of some known or expected keywords like \"spiderman\", \"spider man\" , \"spidey\" , \"spider\" in product title\n",
    "- Fast compared to string_match_with_fuzz().\n",
    "\n",
    "### string_match_with_fuzz() \n",
    "\n",
    "- Uses [Levenshtein Distance](https://medium.com/analytics-vidhya/fuzzy-matching-in-python-2def168dee4a) string matching algorithm.\n",
    "- we first tokenize the text\n",
    "- then take the partial ratio of each text with one keyword `spider`\n",
    "- if any of the text have a match greater than 90 then it will be a match\n",
    "\n",
    "- if we are using string_match_with_rules(), then we have to add more domain specific keywords in our rule search, \n",
    "- But for string_match_with_fuzz() we only had to add a keyword \"spider\". \n",
    "\n",
    "- So if our problem statement have more search keywords, it is always better to use Levenshtein Distance to calculate the match\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e139600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "def clean_white_space(text):\n",
    "    \"\"\"\n",
    "    to clean unwanted white space in text\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def process_title(text):\n",
    "    \"\"\"\n",
    "    to clean the text by lowercasing,\n",
    "    and removing special characters and digits\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = \"\".join([char for char in text if char not in punctuation and not char.isdigit()])\n",
    "    return clean_white_space(text)\n",
    "\n",
    "def string_match_with_fuzz(text, threshold=90):\n",
    "    \"\"\"\n",
    "    to return true if text have a match with fuzz partial ratio\n",
    "    \"\"\"\n",
    "    text = process_title(text)\n",
    "    # tokenize the text using nltk tokenizer\n",
    "    text_list = word_tokenize(text)\n",
    "    ratios = [fuzz.partial_ratio(text_, \"spider\") if len(text_) > 3 else 0 for text_ in text_list]\n",
    "    if any([ratio_ >= threshold for ratio_ in ratios]):\n",
    "        return True\n",
    "    \n",
    "\n",
    "def string_match_with_rules(text):\n",
    "    \"\"\"\n",
    "    to return True if the following keywords are present\n",
    "    in the text\n",
    "    \"\"\"\n",
    "    text = process_title(text)\n",
    "    naive_search = [\"spiderman\" in text, \"spider man\" in text, \"spidey\" in text, \"spider\" in text]\n",
    "    if any(naive_search):\n",
    "        return True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8206bb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product title: SEMAPHORE bobblehead Toys Action Figure and Car Dashboard Interior Accessories(SPIDERMAN) Compatible with Hyundai Verna\n",
      "\n",
      "string match with rules , title match: True\n",
      "time taken to process 8.940696716308594e-05 seconds\n",
      "\n",
      "string match with Levenshtein Distance (partial ratio), title match: True\n",
      "time taken to process 0.004745006561279297 seconds\n"
     ]
    }
   ],
   "source": [
    "title = \"SEMAPHORE bobblehead Toys Action Figure and Car Dashboard Interior Accessories(SPIDERMAN) Compatible with Hyundai Verna\"\n",
    "print(\"product title:\",title)\n",
    "start = time()\n",
    "print(\"\\nstring match with rules , title match:\", string_match_with_rules(title))\n",
    "print(f\"time taken to process {time()-start} seconds\\n\")\n",
    "start = time()\n",
    "print(\"string match with Levenshtein Distance (partial ratio), title match:\", string_match_with_fuzz(title))\n",
    "print(f\"time taken to process {time()-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c186a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product title: Men Full Sleeve Printed Hooded Sweatshirt\n",
      "\n",
      "string match with rules , title match: None\n",
      "time taken to process 0.00017952919006347656 seconds\n",
      "\n",
      "string match with Levenshtein Distance (partial ratio), title match: None\n",
      "time taken to process 0.0004837512969970703 seconds\n"
     ]
    }
   ],
   "source": [
    "title = \"Men Full Sleeve Printed Hooded Sweatshirt\"\n",
    "print(\"product title:\",title)\n",
    "start = time()\n",
    "print(\"\\nstring match with rules , title match:\", string_match_with_rules(title))\n",
    "print(f\"time taken to process {time()-start} seconds\\n\")\n",
    "start = time()\n",
    "print(\"string match with Levenshtein Distance (partial ratio), title match:\", string_match_with_fuzz(title))\n",
    "print(f\"time taken to process {time()-start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df773ada",
   "metadata": {},
   "source": [
    "#### Why fuzz.partial ratio()\n",
    "- For our use case, partial ratio perfomed well in identifying product title, at the same time avoiding unwanted titles matching (when we kept a threshold of 90).\n",
    "\n",
    "- we can also combine more than one ratios score and then match strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf9e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>fuzz.ratio</th>\n",
       "      <th>fuzz.partial_ratio</th>\n",
       "      <th>fuzz.token_sort</th>\n",
       "      <th>fuzz.token_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spidey</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spider</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spiderman</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spider-man</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ironman</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>30.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>super</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>72.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sticker</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>61.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spin</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword  fuzz.ratio  fuzz.partial_ratio  fuzz.token_sort  fuzz.token_set\n",
       "0      spidey   83.333333           90.909091        83.333333       83.333333\n",
       "1      spider  100.000000          100.000000       100.000000      100.000000\n",
       "2   spiderman   80.000000          100.000000        80.000000       80.000000\n",
       "3  spider-man   75.000000          100.000000        75.000000      100.000000\n",
       "4     ironman   30.769231           50.000000        30.769231       30.769231\n",
       "5       super   72.727273           60.000000        72.727273       72.727273\n",
       "6     sticker   61.538462           54.545455        61.538462       61.538462\n",
       "7        spin   60.000000           85.714286        60.000000       60.000000\n",
       "8           d   28.571429          100.000000        28.571429       28.571429"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts = [\"spidey\", \"spider\", \"spiderman\", \"spider-man\", \"ironman\", \"super\", \"sticker\", 'spin', 'd']\n",
    "result = []\n",
    "search_key = 'spider'\n",
    "for test_text in test_texts:\n",
    "    result.append({\"keyword\": test_text,\n",
    "    \"fuzz.ratio\": fuzz.ratio(search_key, test_text), \n",
    "    \"fuzz.partial_ratio\": fuzz.partial_ratio(search_key, test_text),\n",
    "    \"fuzz.token_sort\": fuzz.token_sort_ratio(search_key, test_text),\n",
    "    \"fuzz.token_set\": fuzz.token_set_ratio(search_key, test_text)\n",
    "    })\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ddce8",
   "metadata": {},
   "source": [
    "# String matching Speed comparison, rules vs fuzz on entire datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb0f1499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 740 µs, total: 17.5 ms\n",
      "Wall time: 17.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"relevant_products_string_match\"] = df.title.apply(lambda x: string_match_with_rules(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d120195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 197 ms, sys: 3.29 ms, total: 200 ms\n",
      "Wall time: 200 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"relevant_products_fuzz_match\"] = df.title.apply(lambda x: string_match_with_fuzz(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42e127aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1058, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unidentified_products = df[df.relevant_products_string_match.isnull()]\n",
    "unidentified_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecb343dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_products = df[~df.relevant_products_fuzz_match.isnull()]\n",
    "relevant_products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb8a3d",
   "metadata": {},
   "source": [
    " total 1175 products were identified as relevant products from product title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef4af2",
   "metadata": {},
   "source": [
    "# Remove image url duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c16a4600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1124, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_products = relevant_products.drop_duplicates(subset=['image_url'])\n",
    "relevant_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cf05abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_products = relevant_products.drop_duplicates(subset=['image_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2b86f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'subtitle', 'product_url', 'smart_url', 'product_id',\n",
       "       'image_url', 'total_count', 'next_listing_page_url', 'search_query',\n",
       "       'page', 'relevant_products_string_match',\n",
       "       'relevant_products_fuzz_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f33662f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = relevant_products.loc[:, [\"product_id\", \"title\", \"product_url\",  'image_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ae76edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1124, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8675830",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(\"relevant_products.csv\", index=False, quoting=QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
